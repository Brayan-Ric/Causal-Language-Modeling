{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a5f699-10b0-4b3c-8b2e-5f9be5ea9f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d437bd6e-a4b8-48cd-8d7f-a12d52f17f01",
   "metadata": {},
   "source": [
    "# <center>Inteligencia Artificial</center>\n",
    "#### <center>Profesor: Dr. Hernán D. Merlino </center>\n",
    "\n",
    "\n",
    "## <center>Trabajo Práctico:</center>\n",
    "### <center>  Generar chistes</center>\n",
    "\n",
    "\n",
    "#### **Integrante:**\n",
    "\n",
    "* Brayan Ricaldi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a141c14-cd81-4aa2-8634-601e3ff50df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "import sklearn.preprocessing as skp\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import (\n",
    "    KBinsDiscretizer,\n",
    "    LabelEncoder,\n",
    "    MinMaxScaler,\n",
    "    Normalizer,\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    PowerTransformer,\n",
    "    RobustScaler,\n",
    "    StandardScaler,\n",
    ")\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import (\n",
    "    RegexpTokenizer,\n",
    "    TreebankWordTokenizer,\n",
    "    WhitespaceTokenizer,\n",
    "    WordPunctTokenizer,\n",
    ")\n",
    "from sklearn.feature_extraction.text import (\n",
    "    CountVectorizer,\n",
    "    TfidfVectorizer,\n",
    "    TfidfTransformer,\n",
    ")\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from joblib import dump, load\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e25c40-da8f-4ead-9214-b370feb17396",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./DataSets/shortjokes.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d1c54e-d934-4fdc-bf95-f7e231b4b575",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Joke'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc3783e-ff24-4ce8-9a05-bf18e2f877fc",
   "metadata": {},
   "source": [
    "# Textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05ba3c3-4c2a-40a4-b808-c953c420a9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textacy\n",
    "from textacy import extract\n",
    "from textacy import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b95b7d-800b-4d01-8d73-2e1e4bb8076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df['Joke'][0]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e469a9ea-0fd8-4433-8476-bce018d7c752",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.normalize.whitespace(preprocessing.remove.punctuation(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb1b0aa-9664-4306-bbb8-c543e7fec2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.normalize.whitespace(preprocessing.remove.punctuation(\"Hola ______\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75084cc0-a016-4f7f-895e-d2b84e07e26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.normalize.whitespace(preprocessing.remove.punctuation(\"Hola Dr. house como esta, soy 3-D\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbdf5ef-8b9a-4689-b528-e429345ff7ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711ebeae-af23-40bd-a38a-f0cfed89f7c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aefa4a00-f326-4976-ab93-f5e19f93f5b5",
   "metadata": {},
   "source": [
    "# Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eeb8fd-2f28-4fff-a7f8-4674aa481412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7aaec2db-a55e-4691-825c-5c90333262a0",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a263bf-e0c1-4baf-80c9-511480926082",
   "metadata": {},
   "source": [
    "1. Remover palabras no deseadas (stop words)\n",
    "2. Crear tokens\n",
    "3. Aplicar tokenización al texto\n",
    "4. Crear vocabulario y generar vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a45524-36ea-4a0b-8028-fa093bbc91ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armamos un set con las stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "#stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf619ec-fc9b-46bf-bf32-a2e9b48d8de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(stop_words=stop_words)\n",
    "count_vec.fit(df['Joke'].values.tolist())\n",
    "df_count_vec = count_vec.transform(df['Joke'].values.tolist())\n",
    "df_count_vec.shape\n",
    "\n",
    "# Podemos observar los features que seleccionó el modelo\n",
    "print(count_vec.get_feature_names()[:100])\n",
    "print()\n",
    "\n",
    "print(\"Cantidad de features: \" + str(len(count_vec.get_feature_names())))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80129152-ef7e-48e1-a77d-02364bdb702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec.get_feature_names()[63000:63015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10581f8f-b118-48e5-817d-4ebf1f22ec6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65f328a-e732-4fb2-92b8-aac1cc0568e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Después de ejecutar el modelo obtenemos la siguiente matriz\n",
    "# Las dimensiones son las filas del dataset x la cantidad de features\n",
    "print(df_count_vec.toarray().shape)\n",
    "print()\n",
    "print(df_count_vec.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c13968-7ea4-4d29-9f08-c0daf5529631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4475c405-302e-40cc-bdc7-7d9eda0c9b26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a6d5ee-ec5a-40b3-b02d-bb1b017ad3e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "005525d5-fe81-4047-aedf-ab7f902afce4",
   "metadata": {},
   "source": [
    "# Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311eb5f1-5201-436b-8220-6c2ac7d57a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f21a57e-3a15-4ca8-90e2-1389cbd820cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31278567-3506-410a-9b96-19a039f77436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "import pandas as pd\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139d70e8-4c6f-48d6-a1e0-6623a2f2f572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "\n",
    "tokenizer = Tokenizer(BPE())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c737057-7028-4443-a73f-bdfb3e0a836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(BPE())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77afb2de-905e-4ad9-8453-c38b7c27f076",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58a4919-dd55-419e-ba51-791d1972567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1[\"example_1\"] = [\"Hola como estas?\", \"Y tuuuuuuuuuuuuuu no se\"]\n",
    "df_1[\"example_12\"] = [\"Ia es el futuro\", \"Vamos a aprobar la materia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338e153c-cdb2-4453-aa80-57e7ea5b789d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd886a95-6670-408a-b7ef-03f45cd70ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ds.dataset(pa.Table.from_pandas(df_1).to_batches())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f117847-40bb-41ea-ab15-e009782b2483",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f65a60-82dd-44ea-90dc-3ff360a41330",
   "metadata": {},
   "outputs": [],
   "source": [
    "hg_dataset = Dataset(pa.Table.from_pandas(df_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038d4136-704f-4218-816a-d5607aef74f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hg_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c7e194-00d2-4c7d-bdbd-fb8e6f610e56",
   "metadata": {},
   "source": [
    "# GPT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23c750d-d6a6-46d7-a001-12d759ac8e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "import sklearn.preprocessing as skp\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import (\n",
    "    KBinsDiscretizer,\n",
    "    LabelEncoder,\n",
    "    MinMaxScaler,\n",
    "    Normalizer,\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    PowerTransformer,\n",
    "    RobustScaler,\n",
    "    StandardScaler,\n",
    ")\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import (\n",
    "    RegexpTokenizer,\n",
    "    TreebankWordTokenizer,\n",
    "    WhitespaceTokenizer,\n",
    "    WordPunctTokenizer,\n",
    ")\n",
    "from sklearn.feature_extraction.text import (\n",
    "    CountVectorizer,\n",
    "    TfidfVectorizer,\n",
    "    TfidfTransformer,\n",
    ")\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from joblib import dump, load\n",
    "\n",
    "pd.options.display.max_columns = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a169fb-322d-48c2-9b83-d42812182bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b407bbe1-4daa-4d5f-84e2-848fc9b16f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./DataSets/shortjokes.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1310d21-e414-492a-9948-59a584c8d90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4af73b-37c3-4a29-8ac3-2f545c3efab2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638f10e4-5f74-419d-9ba8-f0ea764307d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chistes = df.Joke.to_numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bc1ced-4384-42cc-9013-74c0947af52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chistes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d102d0-cd85-408e-beac-56b8b3703591",
   "metadata": {},
   "source": [
    "Examinare las longitudes de cada chiste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604e496f-26b2-4b68-913b-178838fbe739",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37838ea7-332d-4a3d-bf09-eb2425daf4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(\"./tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c022aa01-fa1f-4b6a-8f50-b08f0371498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = tokenizer(chistes, padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b33ead9-6b1d-4320-9263-6985f60ba86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1771bdde-c824-4739-a1f4-fd1b237963ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6675aaab-8c43-453c-af15-1559109e9533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d174f2b-57c9-41db-8830-6cbd7aacaa72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08d4464a-028b-45af-b221-a3d190141966",
   "metadata": {},
   "source": [
    "# GPT 2 - V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d6150c0-8b0b-4b90-a183-1587adf40b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "import sklearn.preprocessing as skp\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import (\n",
    "    KBinsDiscretizer,\n",
    "    LabelEncoder,\n",
    "    MinMaxScaler,\n",
    "    Normalizer,\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    PowerTransformer,\n",
    "    RobustScaler,\n",
    "    StandardScaler,\n",
    ")\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import (\n",
    "    RegexpTokenizer,\n",
    "    TreebankWordTokenizer,\n",
    "    WhitespaceTokenizer,\n",
    "    WordPunctTokenizer,\n",
    ")\n",
    "from sklearn.feature_extraction.text import (\n",
    "    CountVectorizer,\n",
    "    TfidfVectorizer,\n",
    "    TfidfTransformer,\n",
    ")\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from joblib import dump, load\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7ffa476-adbb-4175-8080-e812967391ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-02 19:50:10.078284: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1cc2c8-812e-42b7-a18c-defa5368666a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36e59531-9ac8-4919-adf8-74262c84c3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Joke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[me narrating a documentary about narrators] \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Telling my daughter garlic is good for you. Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>I've been going through a really rough period ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>If I could have dinner with anyone, dead or al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Two guys walk into a bar. The third guy ducks.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               Joke\n",
       "0   1  [me narrating a documentary about narrators] \"...\n",
       "1   2  Telling my daughter garlic is good for you. Go...\n",
       "2   3  I've been going through a really rough period ...\n",
       "3   4  If I could have dinner with anyone, dead or al...\n",
       "4   5     Two guys walk into a bar. The third guy ducks."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./DataSets/shortjokes.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cae4af3-ce9f-48cc-8f66-6b6cd2466ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231657, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d521b40-b264-4752-8906-31d7547b5512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Joke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[me narrating a documentary about narrators] \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Telling my daughter garlic is good for you. Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I've been going through a really rough period ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If I could have dinner with anyone, dead or al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Two guys walk into a bar. The third guy ducks.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Joke\n",
       "0  [me narrating a documentary about narrators] \"...\n",
       "1  Telling my daughter garlic is good for you. Go...\n",
       "2  I've been going through a really rough period ...\n",
       "3  If I could have dinner with anyone, dead or al...\n",
       "4     Two guys walk into a bar. The third guy ducks."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['ID'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6dfab30-af1e-4389-883f-84b57569ca3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231657, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bf326f-acd5-4007-9ba6-67b4dd94d4da",
   "metadata": {},
   "source": [
    "## Divido el dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57375691-1e8a-4823-a1b9-d09395f39e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2e2303d-7df5-43ac-8370-06486f29375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.30, random_state=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "396bb150-ceb1-42d7-8d16-7e78201a8707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Joke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82415</th>\n",
       "      <td>I've said it before and I'll say it again: the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115989</th>\n",
       "      <td>There should be a \"Life of Pi\" TV show, where ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66572</th>\n",
       "      <td>What do you call a cow that has a record playe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57167</th>\n",
       "      <td>Steve Jobs's death was a conspiracy. He was mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186795</th>\n",
       "      <td>If I really wanted to end my life I'd probably...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Joke\n",
       "82415   I've said it before and I'll say it again: the...\n",
       "115989  There should be a \"Life of Pi\" TV show, where ...\n",
       "66572   What do you call a cow that has a record playe...\n",
       "57167   Steve Jobs's death was a conspiracy. He was mu...\n",
       "186795  If I really wanted to end my life I'd probably..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22f36972-7a53-4966-9fc8-a1ea9d9a5c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Joke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100556</th>\n",
       "      <td>I found out I was dyslexic when I got invited ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222309</th>\n",
       "      <td>In addition to Billie Chin and little Sammy Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77030</th>\n",
       "      <td>What do you call a dictionary on drugs? Addict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208533</th>\n",
       "      <td>Cop: What happened? Me: A Smart Car hit one of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77516</th>\n",
       "      <td>What's Better, British or German Sausages Brit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Joke\n",
       "100556  I found out I was dyslexic when I got invited ...\n",
       "222309  In addition to Billie Chin and little Sammy Ch...\n",
       "77030   What do you call a dictionary on drugs? Addict...\n",
       "208533  Cop: What happened? Me: A Smart Car hit one of...\n",
       "77516   What's Better, British or German Sausages Brit..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cabcacbd-5c63-4530-ba77-db78094ceae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc10699f-9f38-44cd-8a03-3edd6050adcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162159, 1)\n",
      "(69498, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f5a658-736a-4784-a30c-090a3a5f3f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f520da7-cac7-44ab-84e8-0cf368c351db",
   "metadata": {},
   "source": [
    "## Creo los DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf0d7957-cdbe-4f2d-9624-d71e1835655c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "import pandas as pd\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33040ff3-b0b9-47ed-8e10-7e678fd8b102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Joke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I've said it before and I'll say it again: the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There should be a \"Life of Pi\" TV show, where ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What do you call a cow that has a record playe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Steve Jobs's death was a conspiracy. He was mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If I really wanted to end my life I'd probably...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Joke\n",
       "0  I've said it before and I'll say it again: the...\n",
       "1  There should be a \"Life of Pi\" TV show, where ...\n",
       "2  What do you call a cow that has a record playe...\n",
       "3  Steve Jobs's death was a conspiracy. He was mu...\n",
       "4  If I really wanted to end my life I'd probably..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6b6c97e-1db5-4eaa-9740-4cf67f420f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = Dataset(pa.Table.from_pandas(train))\n",
    "df_test = Dataset(pa.Table.from_pandas(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "436c7a20-d5a5-49a6-991b-615d5873faa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Joke'],\n",
       "    num_rows: 162159\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7857f1dc-ba0f-4265-83ce-f56eaa3147c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Joke'],\n",
       "    num_rows: 69498\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4619bffd-bf59-4b99-beb3-6136b7c95b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ca1c29a-9e61-419a-aa94-06677753f751",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joke = DatasetDict(\n",
    "    {\n",
    "        \"train\": df_train,  \n",
    "        \"valid\": df_test,  \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "918baa31-ee3b-4d00-a36e-3a834f61d119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Joke'],\n",
       "        num_rows: 162159\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['Joke'],\n",
       "        num_rows: 69498\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_joke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f553bb-67c6-4a02-b5dd-b5c3b92d86fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2571af-7750-4de8-96da-984a2c21c14d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd3a1ba-587d-4c0d-abe0-c9321f0553ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086e6296-3b5f-4056-a73a-f0ed671d2548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aca1650-9b57-4c28-9aa6-b390fb5ba151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b96adf-7f90-4409-8cfd-244aac75957b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09838163-b191-4c9f-a242-99e58028cdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d8d4b7-92d3-467f-b9e1-3dfe9254b6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0278f88e-e0c9-4144-816d-33e3faad7171",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"huggingface-course/code-search-net-tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bd2d3a-09cc-434b-907e-ada432903215",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(element):\n",
    "    outputs = tokenizer(\n",
    "        element[\"Joke\"],\n",
    "        truncation=True,\n",
    "        max_length=context_length,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_length=True,\n",
    "    )\n",
    "    input_batch = []\n",
    "    for length, input_ids in zip(outputs[\"length\"], outputs[\"input_ids\"]):\n",
    "        if length == context_length:\n",
    "            input_batch.append(input_ids)\n",
    "    return {\"input_ids\": input_batch}\n",
    "\n",
    "\n",
    "tokenized_datasets = df_joke.map(\n",
    "    tokenize, batched=True, remove_columns=df_joke[\"train\"].column_names\n",
    ")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7679318b-718c-437d-971c-0b2aee442686",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenized_datasets['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b229228-b6ba-4d80-915a-6870f9d5c0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_length= list(range(10, 31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e8a59b-b1c9-474d-8e89-cca717774593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(element):\n",
    "    outputs = tokenizer(\n",
    "        element[\"Joke\"],\n",
    "        truncation=True,\n",
    "        max_length=context_length,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_length=True,\n",
    "    )\n",
    "    input_batch = []\n",
    "    for length, input_ids in zip(outputs[\"length\"], outputs[\"input_ids\"]):\n",
    "        if length == context_length:\n",
    "            input_batch.append(input_ids)\n",
    "    return {\"input_ids\": input_batch}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05b3475-5d18-4161-9887-0802bd95b964",
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_train=[]\n",
    "valores_test=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3321732b-f848-4b2d-9188-b9ac890a6b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for length in range_length:\n",
    "    context_length = length\n",
    "    tokenized_datasets = df_joke.map(\n",
    "        tokenize, batched=True, remove_columns=df_joke[\"train\"].column_names\n",
    "    )\n",
    "    valores_train.append(len(tokenized_datasets['train']))\n",
    "    valores_test.append(len(tokenized_datasets['valid']))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91a50a9-502d-4f40-9ae0-85b486efa215",
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4113dfa3-6cb5-4103-b023-f39a169d4a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c91733-33d2-43b5-96c4-115b495e66e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ea44d1-e277-4ce2-9726-fe4202c5beb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(valores_train, linestyle = 'dotted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee3ee1c-55cf-4d0a-a38e-a499944549af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f93c2e-85cb-4858-a314-cb5331f0cc50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b40f62b-3db6-47bc-bc78-c5b95ed2d558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6658b06-1f3a-48de-a4f9-b6ef6916d2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd356cf3-0f83-422a-90ba-1e897e15525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dd6c5f-8e1c-4966-8d46-91ddc89b60a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f95a981-4b37-49c6-acfb-8f4f55819939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf23c910-6136-4998-ab73-e93de53a51cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joke[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48999905-9d5e-48de-b9dc-8be58a7a7f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5d9080-c912-46e6-b64a-c7831abfac56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4c9a3c-0d43-4af1-9867-f535875df689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397840d0-d1bf-46f0-aac3-47d1fcbdd400",
   "metadata": {},
   "outputs": [],
   "source": [
    "miLista = [\"Estas\", \"son\", \"muchas\", \"palabras\", \".\", \"Hola\", \"soy\", \"Luis\", \".\", \"Hola\"]\n",
    "salida = []\n",
    "linea = \"\"\n",
    "for palabra in miLista:\n",
    "    if palabra == '.':\n",
    "        linea += ' '.join(salida) + '.\\n'\n",
    "        salida = []\n",
    "    else:\n",
    "        salida.append(palabra)\n",
    "\n",
    "if salida:\n",
    "    linea += ' '.join(salida)\n",
    "print(linea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a74f4d-dfaf-4652-b116-fd4009716c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "chistes = [\"Estas\", \"son\", \"muchas\", \"palabras\", \".\", \"Hola\", \"soy\", \"Luis\", \".\", \"Hola\"]\n",
    "salida = []\n",
    "linea = \"\"\n",
    "for palabra in miLista:\n",
    "    if palabra == '.':\n",
    "        linea += ' '.join(salida) + '.\\n'\n",
    "        salida = []\n",
    "    else:\n",
    "        salida.append(palabra)\n",
    "\n",
    "if salida:\n",
    "    linea += ' '.join(salida)\n",
    "print(linea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4dc84f-6148-4985-a192-64dc781b3505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1d2a76-81c0-42d3-b797-84a64add17f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74093be-e519-4b3e-86de-87b0ea60641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['Hola, como estas', 'Bien y vos?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d90386-c0de-45d3-a71c-9fde1ef51554",
   "metadata": {},
   "outputs": [],
   "source": [
    "'\\n'.join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe1989e-3d46-48fb-ab56-8626b6cca433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee82ffc-bba4-4f70-91ab-59a8c65e9027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbd63ae-ca5b-4fd3-b68c-7e84cfe36672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "context_length = 128\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"huggingface-course/code-search-net-tokenizer\")\n",
    "\n",
    "outputs = tokenizer(\n",
    "    raw_datasets[\"train\"][:2][\"content\"],\n",
    "    truncation=True,\n",
    "    max_length=context_length,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_length=True,\n",
    ")\n",
    "\n",
    "print(f\"Input IDs length: {len(outputs['input_ids'])}\")\n",
    "print(f\"Input chunk lengths: {(outputs['length'])}\")\n",
    "print(f\"Chunk mapping: {outputs['overflow_to_sample_mapping']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5f3206-2de6-428b-a900-967fe6972a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23420aca-814b-40dd-a27f-bdc0c8f7eed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398e0f1e-8985-4161-b1b2-bf77dc3605b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff2c02d-541a-4788-8346-113cfc80cb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "ds_train = load_dataset(\"huggingface-course/codeparrot-ds-train\", split=\"train\")\n",
    "ds_valid = load_dataset(\"huggingface-course/codeparrot-ds-valid\", split=\"validation\")\n",
    "\n",
    "raw_datasets = DatasetDict(\n",
    "    {\n",
    "        \"train\": ds_train,  # .shuffle().select(range(50000)),\n",
    "        \"valid\": ds_valid,  # .shuffle().select(range(500))\n",
    "    }\n",
    ")\n",
    "\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cdbbd5-4683-4f9b-badc-d0ab851fdb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "432"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d277dea3-1631-4bff-a1a2-4d8dba8c54cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e73e7cd-0443-421a-bda5-52c497b8d227",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbbfe0e-6644-4a41-b19d-4397f1adbb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae300dd-1fbe-4f47-a663-d1d69b0e1251",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bf9930-876e-4e79-9f92-ba1a920024b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
