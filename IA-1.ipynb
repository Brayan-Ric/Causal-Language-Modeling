{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d437bd6e-a4b8-48cd-8d7f-a12d52f17f01",
   "metadata": {},
   "source": [
    "# <center>Inteligencia Artificial</center>\n",
    "#### <center>Profesor: Dr. Hernán D. Merlino </center>\n",
    "\n",
    "\n",
    "## <center>Trabajo Práctico:</center>\n",
    "### <center>  Generar chistes</center>\n",
    "\n",
    "\n",
    "#### **Integrante:**\n",
    "\n",
    "* Brayan Ricaldi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ea8907-9c01-4e36-bbd0-54f77f431cfd",
   "metadata": {},
   "source": [
    "## Explicacion previa:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f33e335-27a6-48ec-b197-a80bbae73039",
   "metadata": {},
   "source": [
    "Utilizare el tipo de dato Arrow y no Pandas. Por los siguientes motivos:\n",
    "   - Arrow esta diseñado para el procesamiento de datos de alto rendimiento y representa  cada conjunto de datos similar a una tabla con un formato en columna de memoria.\n",
    "   - Permite multiplces procesos sin mover ni copiar los datos, estoo hace que iterar los datos sea realmente rapido.\n",
    "   \n",
    "Por estos motivos he podido crear mi modelo y estudiarlo, sin problemas de memoria.<br>\n",
    "Para mas detalles: https://huggingface.co/course/chapter5/4?fw=pt.\n",
    "\n",
    "Team Arrow!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc54ec04-ab31-4309-ac78-73aca16879ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7fb8a6-127b-4369-8081-b8c1eeea7bc5",
   "metadata": {},
   "source": [
    "## Descargando los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c045dfee-0be0-4c78-84b2-fad6bdb6d5ae",
   "metadata": {},
   "source": [
    "<p>Para este modelo usare 2 conjunto de datos.</p>\n",
    "<p>Fuente:</p>\n",
    "<ul>\n",
    "    <li><b>ds_1</b>: https://www.kaggle.com/datasets/abhinavmoudgil95/short-jokes?resource=download</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7155887-c767-48a9-9876-ee93f070f0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "476521cd-95f4-4bcd-bc70-b4724a5ae5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/brar2/.cache/huggingface/datasets/csv/default-b9f3f83369114b0d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['ID', 'Joke'],\n",
       "    num_rows: 231657\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\n",
    "                    \"csv\",\n",
    "                    data_files=\"./DataSets/shortjokes.csv\",\n",
    "                    split=\"train\"\n",
    "                    )\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34cd4ad1-6fff-413b-970e-a456ff7792ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at C:\\Users\\brar2\\.cache\\huggingface\\datasets\\csv\\default-b9f3f83369114b0d\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-4d4a8d62df80e9e8.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> ID: 133560\n",
      ">>> Joke: I'm not John Madden, just John Disappointeden.\n",
      "\n",
      ">>> ID: 229327\n",
      ">>> Joke: Scientists have recently discovered the existence of a mentally unstable microscopic parasite on the moon... Apparently it's a real lunatic\n"
     ]
    }
   ],
   "source": [
    "#Formato usado: Apache Arrow\n",
    "muestra = ds.shuffle(seed=0).select(range(2))\n",
    "\n",
    "for i in muestra:\n",
    "    print(f\"\\n>>> ID: {i['ID']}\")\n",
    "    print(f\">>> Joke: {i['Joke']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d3cfa1-e432-44a1-ac4b-a47a662236f1",
   "metadata": {},
   "source": [
    "## Estudio del dataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f727d58-7b34-48d7-acdc-01fada796183",
   "metadata": {},
   "source": [
    "Convierto el DataSet a formato pandas, para mejor estudio de los datos y visualizaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5898c2ea-dfbd-4c91-a8d4-7422734d0307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = ds.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5603329f-ef29-4352-857e-e983a02764db",
   "metadata": {},
   "source": [
    "<p><b>Busco la cantidad de None del dataSet</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ae54960-31e8-47b8-8911-df766f65835d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 231657 entries, 0 to 231656\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   ID      231657 non-null  int64 \n",
      " 1   Joke    231657 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0753aad-bb7c-4b8e-b29b-b7020e4d7cba",
   "metadata": {},
   "source": [
    "Observo que el dataSet no tiene ningun None, en otras palabras no tiene ningun dato faltante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb4725f-5bac-452a-a4f9-617f700153c6",
   "metadata": {},
   "source": [
    "<p><b>Busco la cantidad de datos repetidos</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8130fae-b320-4e81-8aec-0535eb976a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cantidad de datos repetidos: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\" Cantidad de datos repetidos: {sum(df.duplicated(keep='first'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd37fd95-2e4b-4bdf-8d7f-d4069180c90b",
   "metadata": {},
   "source": [
    "No tengo ningun dato repetido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a648e5c5-78c7-4149-9552-3c4b25a16e05",
   "metadata": {},
   "source": [
    "<p><b>Estudio la longitud de los chistes</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eb9abe-0341-4d1f-a409-9519b5dba24c",
   "metadata": {},
   "source": [
    "Ahora voy a estudiar la longitud de los chistes, el separador sera el espacio(\" \").<br>\n",
    "La longitud de cada chiste se consegira con el dataSet tipo Arrow para optimizar la velocidad y la ram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc64c8ff-7e76-4a1e-a01d-a11d23572b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def longitud(chiste):\n",
    "    return {\"joke_len\": len(chiste[\"Joke\"].split())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d22c8b2e-b391-4673-be5f-ed1247f25691",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\brar2\\.cache\\huggingface\\datasets\\csv\\default-b9f3f83369114b0d\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-1b084c612300eea2.arrow\n"
     ]
    }
   ],
   "source": [
    "ds = ds.map(longitud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ee2c64f-f001-4b71-8869-0b26e9413027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Joke</th>\n",
       "      <th>joke_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[me narrating a documentary about narrators] \"...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Telling my daughter garlic is good for you. Go...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>I've been going through a really rough period ...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>If I could have dinner with anyone, dead or al...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Two guys walk into a bar. The third guy ducks.</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               Joke  joke_len\n",
       "0   1  [me narrating a documentary about narrators] \"...        15\n",
       "1   2  Telling my daughter garlic is good for you. Go...        18\n",
       "2   3  I've been going through a really rough period ...        23\n",
       "3   4  If I could have dinner with anyone, dead or al...        16\n",
       "4   5     Two guys walk into a bar. The third guy ducks.        10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ds.to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc30f31b-47b7-40b3-b50b-8d090912e834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Longitud de los chistes')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, dpi=100, figsize=(10, 7))\n",
    "sns.histplot(\n",
    "    x=\"joke_len\",\n",
    "    data=df,\n",
    "    binwidth=5,\n",
    "    color=\"#ffff00\",\n",
    ")\n",
    "axes.set_title(\"Longitud de los chistes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f48bd2-14c4-4539-a82e-43d800a7b7ee",
   "metadata": {},
   "source": [
    "Observo que hay chistes de longitud menor a 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59d1ab22-c777-47d6-9645-72d6585da928",
   "metadata": {},
   "outputs": [],
   "source": [
    "longitud_minima_chistes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06a77d9d-88ce-42dc-93e4-683292e11724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Joke</th>\n",
       "      <th>joke_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>Ted Cruz getting elected.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>481</td>\n",
       "      <td>Political Joke The Economy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>618</td>\n",
       "      <td>Broken pencils... ...are pointless.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>669</td>\n",
       "      <td>Prostitutes hate trick-or-treaters.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>672</td>\n",
       "      <td>The definition of spin</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231147</th>\n",
       "      <td>231148</td>\n",
       "      <td>Obamacare.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231372</th>\n",
       "      <td>231373</td>\n",
       "      <td>Evolution: True science fiction.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231473</th>\n",
       "      <td>231474</td>\n",
       "      <td>Jesus Saves.... Moses invests.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231550</th>\n",
       "      <td>231551</td>\n",
       "      <td>Strap-on backwards spells No-parts.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231575</th>\n",
       "      <td>231576</td>\n",
       "      <td>Canada's navy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1156 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                 Joke  joke_len\n",
       "38          39            Ted Cruz getting elected.         4\n",
       "480        481           Political Joke The Economy         4\n",
       "617        618  Broken pencils... ...are pointless.         4\n",
       "668        669  Prostitutes hate trick-or-treaters.         3\n",
       "671        672               The definition of spin         4\n",
       "...        ...                                  ...       ...\n",
       "231147  231148                           Obamacare.         1\n",
       "231372  231373     Evolution: True science fiction.         4\n",
       "231473  231474       Jesus Saves.... Moses invests.         4\n",
       "231550  231551  Strap-on backwards spells No-parts.         4\n",
       "231575  231576                        Canada's navy         2\n",
       "\n",
       "[1156 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"joke_len\"] < longitud_minima_chistes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6598521-6181-4944-9022-4263901779b3",
   "metadata": {},
   "source": [
    "Me doy cuenta que si son algo chistosos por ejemplo los chistes:\n",
    "   - Canada's navy. (\"La marina de Canada\") #ID = 231575\n",
    "   - Ted Cruz getting elected. (\"Ted Cruz siendo elegido\") #ID = 39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a50dcaf5-cb25-40eb-a1b6-133947458594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje del total de chistes menores a 5: 0.49901362790677595%\n"
     ]
    }
   ],
   "source": [
    "chistes_menores_cinco = df[df[\"joke_len\"] < longitud_minima_chistes].shape[0]\n",
    "chistes_total = df.shape[0]\n",
    "print(f\"Porcentaje del total de chistes menores a 5: {(100 * chistes_menores_cinco) / chistes_total}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6d2c94-5547-4fe6-9f04-41b8a5e7885e",
   "metadata": {},
   "source": [
    "<p>Observo que si los elimino perderia menos de 1% de mi dataSet.</p>\n",
    "<p>Optare por no eliminarlos.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5acf67f-b940-4f8a-ac84-14812cc32ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/231657 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/207808 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['ID', 'Joke', 'joke_len'],\n",
       "    num_rows: 198172\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds.filter(lambda x: x[\"joke_len\"] >= 10)\n",
    "ds = ds.filter(lambda x: x[\"joke_len\"] <= 30)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311436b4-259b-4e2f-b0d7-1bb92e4bb303",
   "metadata": {},
   "source": [
    "## Preparando los dataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341ad110-ba90-4614-b907-0b7dc0a090d0",
   "metadata": {},
   "source": [
    "Elimino el feature ID porque no brinda informacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0a7b453-c134-4c91-bcec-a84aa56d2d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Joke'],\n",
       "    num_rows: 198172\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds.remove_columns([\"joke_len\", \"ID\"])\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c77538-c5a0-41a8-801f-3aa67acb83b1",
   "metadata": {},
   "source": [
    "Cambio el nombre del feature \"Joke\" por \"joke\", por comodidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6ced9d0-3954-4352-b882-74be5e207853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['joke'],\n",
       "    num_rows: 198172\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds.rename_column(\"Joke\", \"joke\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cfd703-b173-4189-bb80-bc06d8772e02",
   "metadata": {},
   "source": [
    "Elimino las etiquetas HTML de los chistes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cca1821b-c12e-49e0-84e5-f5b2c9d42cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/198172 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['joke'],\n",
       "    num_rows: 198172\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import html\n",
    "ds = ds.map(lambda x: {\"joke\": html.unescape(x[\"joke\"])})\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10c5a0c-e745-4739-9ce9-92e6a2662d9a",
   "metadata": {},
   "source": [
    "## Dividio el dataSet en train y test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff7e94e-74a7-46b8-be50-e1951ee3f5e2",
   "metadata": {},
   "source": [
    "Divido el dataSet en 2:\n",
    "   - Train: 70%.\n",
    "   - Test: 30%. <br>\n",
    "\n",
    "Para division sera de forma aleatoria con el parametro shuffle=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a7e6658-a438-4000-bce0-9d2bc6acf14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_joke = ds.train_test_split(\n",
    "                                test_size=0.3, \n",
    "                                shuffle=True,\n",
    "                                seed=1\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d12ba582-ce22-45c9-ba07-264b3e75a8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['joke'],\n",
       "        num_rows: 138720\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['joke'],\n",
       "        num_rows: 59452\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_joke"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89711cb-81cd-4dfb-8314-5afc82270719",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6e8661-6fa6-4136-b9f3-4bac6d290dec",
   "metadata": {},
   "source": [
    "## Tokenizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb7d3780-cbb4-45f7-862f-d1e0bee61ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e815d89-6511-469e-b70f-784a42edc2a7",
   "metadata": {},
   "source": [
    "La longitud de los contextos sera de 128, por temas de optimizar la memoria.<br>\n",
    "Si tiene una memoria mayor y un cpu potente lo puede cambiar por 1024 o 2048."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "246e032f-ef4a-4284-8021-b5b126540324",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94381703-7dd0-4371-9083-011e920d837a",
   "metadata": {},
   "source": [
    "Longitud del contexto: Cantidad de tokens que debe tener la oracion. <br>\n",
    "#Importante: AGREGAR IMAGEN DE EXPLICACION."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60200a3-9942-42ce-a4cb-3a1b45da97a9",
   "metadata": {},
   "source": [
    "Descargo un tokenizador ya entrenado.<br>\n",
    "Cada token ya tiene establecido su propio ID <br>\n",
    "#IMPORTANTE: AGREGAR IMAGEN EXPLICANDO ESTE PROCESO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f2284fc-1a37-4e8b-9eb1-d839aee5da95",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"huggingface-course/code-search-net-tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f4b208f-6e2c-4288-9c6e-85e9b63e5dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/138720 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/59452 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids'],\n",
       "        num_rows: 138720\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids'],\n",
       "        num_rows: 59452\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    outputs = tokenizer(\n",
    "        examples[\"joke\"], \n",
    "        truncation=False,#True\n",
    "        return_overflowing_tokens=True,\n",
    "        return_length=True,\n",
    "        add_special_tokens=True,\n",
    "        max_length=context_length,\n",
    "    )\n",
    "    \n",
    "    input_batch = []\n",
    "    for length, input_ids in zip(outputs[\"length\"], outputs[\"input_ids\"]):\n",
    "        input_batch.append(input_ids + [tokenizer.eos_token_id])\n",
    "        #if length == 15:\n",
    "        #input_batch.append(input_ids)\n",
    "    return {\"input_ids\": input_batch}\n",
    "\n",
    "\n",
    "\n",
    "# Use batched=True to activate fast multithreading!\n",
    "tokenized_datasets = ds_joke.map(\n",
    "    tokenize_function, batched=True, remove_columns=ds_joke[\"train\"].column_names)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00574f4-6ae8-4484-bc68-533b750e3077",
   "metadata": {},
   "source": [
    "Voy a estudiar la longitud de los tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d2dd60-0165-41ed-a423-38ad3ca28be0",
   "metadata": {},
   "source": [
    "Imprimo la cantidad de tokens de los 15 1eros chistes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b743cb5-f375-4a1c-a32a-f4453a75e2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Review 0 length: 28'\n",
      "'>>> Review 1 length: 30'\n",
      "'>>> Review 2 length: 18'\n",
      "'>>> Review 3 length: 31'\n",
      "'>>> Review 4 length: 39'\n",
      "'>>> Review 5 length: 18'\n",
      "'>>> Review 6 length: 23'\n",
      "'>>> Review 7 length: 23'\n",
      "'>>> Review 8 length: 34'\n",
      "'>>> Review 9 length: 22'\n",
      "'>>> Review 10 length: 21'\n",
      "'>>> Review 11 length: 26'\n",
      "'>>> Review 12 length: 33'\n",
      "'>>> Review 13 length: 17'\n",
      "'>>> Review 14 length: 52'\n"
     ]
    }
   ],
   "source": [
    "tokenized_samples = tokenized_datasets[\"train\"][:15]\n",
    "\n",
    "for idx, sample in enumerate(tokenized_samples[\"input_ids\"]):\n",
    "    print(f\"'>>> Review {idx} length: {len(sample)}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c032f32e-a629-491c-8ff8-5f27dacdebbb",
   "metadata": {},
   "source": [
    "Como se menciono anteriormente, voy a trabajar con un contexto de 128 tokens, asi que debo hacer que cada chiste tenga 128 tokens ni mas ni menos.<br>\n",
    "Pero eso es un problema, ya que estamos observando que los 1eros 15 chistes estan compuestos por menos de 65 tokens.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d1e40c-b8c4-430f-bdef-d98a38d50881",
   "metadata": {},
   "source": [
    "<h3><b>¿Que se podra hacer? </b></h3>\n",
    "<p>Tenemos 4 posibles soluciones:<p>\n",
    "<ol>\n",
    "   <li> Solo quedarnos con los chistes formados por 128 tokens.</li>\n",
    "   <li> Solo quedarnos con los chistes mayores o igual a 128 tokens, y luego truncar su valores(solo quedarme con los 1ero 128 tokens).</li>\n",
    "   <li> Modificiar la longitud del contexto, un valor menor como ya vimos que los 1eros 15 chistes son de una longitud muy menor a 128, podemos cambiar el contexto a 20.\n",
    "   <li> Concatenar todos los chistes y luego dividirlo en segmentos de 128 tokens.\n",
    "</ol>\n",
    "<p><b>Problemas:</b></p>\n",
    "<ul>\n",
    "    <li> Las soluciones 1 y 2 no serian las mas convenientes para nuestro problema, ya vimos que los 1eros 15 chistes eran menores a 128 tokens, perderiamos muchos datos al solo quedarme con los chistes largos.\n",
    "    <li> Con la solucion 3 no perderia datos pero si contexto en los chistes, al solo quedarme con la parte inicial los chistes perderian significado.\n",
    "    <li> La solucion 4 es la mejor. Ahora se explicara el <b>porque</b>.\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fc64dc-ed28-4574-acc9-60b36095c483",
   "metadata": {},
   "source": [
    "#IMPORTANTE: COMPLETAR <br>\n",
    "Explicacion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4758485-8463-49ba-b47b-21a887375dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Concatenated reviews length: 415'\n"
     ]
    }
   ],
   "source": [
    "concatenated_examples = {\n",
    "    k: sum(tokenized_samples[k], []) for k in tokenized_samples.keys()\n",
    "}\n",
    "total_length = len(concatenated_examples[\"input_ids\"])\n",
    "print(f\"'>>> Concatenated reviews length: {total_length}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c43c7f9c-149a-429a-ace9-f2fedbea8ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = context_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4ee987-8c1e-4096-8d74-1f364f469ad5",
   "metadata": {},
   "source": [
    "Una forma sencilla seria unir los tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c93b1616-7185-4fa8-a550-752701c01f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Chunk length: 15'\n",
      "'>>> Chunk length: 15'\n",
      "'>>> Chunk length: 15'\n",
      "'>>> Chunk length: 15'\n",
      "'>>> Chunk length: 15'\n",
      "'>>> Chunk length: 15'\n",
      "'>>> Chunk length: 15'\n",
      "'>>> Chunk length: 15'\n",
      "'>>> Chunk length: 15'\n",
      "'>>> Chunk length: 15'\n",
      "'>>> Chunk length: 15'\n",
      "'>>> Chunk length: 15'\n",
      "'>>> Chunk length: 15'\n",
      "'>>> Chunk length: 15'\n",
      "'>>> Chunk length: 15'\n",
      "'>>> Chunk length: 15'\n",
      "'>>> Chunk length: 15'\n",
      "'>>> Chunk length: 15'\n",
      "'>>> Chunk length: 15'\n",
      "'>>> Chunk length: 15'\n",
      "'>>> Chunk length: 15'\n",
      "'>>> Chunk length: 15'\n",
      "'>>> Chunk length: 15'\n",
      "'>>> Chunk length: 15'\n",
      "'>>> Chunk length: 15'\n",
      "'>>> Chunk length: 15'\n",
      "'>>> Chunk length: 15'\n",
      "'>>> Chunk length: 10'\n"
     ]
    }
   ],
   "source": [
    "chunks = {\n",
    "    k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "    for k, t in concatenated_examples.items()\n",
    "}\n",
    "\n",
    "for chunk in chunks[\"input_ids\"]:\n",
    "    print(f\"'>>> Chunk length: {len(chunk)}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c21f4ee-2042-42b7-bae2-41e661de7c12",
   "metadata": {},
   "source": [
    "<p> Observo que el ultimo dato, tiene 15 tokens. </p>\n",
    "<p>Tenemos 2 posibles soluciones.</p>\n",
    "<ol>\n",
    "    <li> Completar el dato con id que significan \"vacio\", para Arrow el 0 es el id vacio</li>\n",
    "    <li> ELiminar el dato</li>\n",
    "</ol>\n",
    "<p>En este caso se elegira la opcion 2.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592fd4b8-c4b9-40f5-aeeb-d66590c7e44f",
   "metadata": {},
   "source": [
    "Ahora recreare todo lo hecho con el dataSet completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7bad9d39-6e0d-44ed-8c46-fad1a2d060c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # Concateno todo el texto\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    # Calculo la longitud de los textos concatenados\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # Si el ultimo fragmento es mas pequenio que la \"longitud del contexto\" sera eliminado.\n",
    "    total_length = (total_length // chunk_size) * chunk_size\n",
    "    # Hago un split del tamanio de la \"longitud del contexto\"\n",
    "    result = {\n",
    "        k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03aaeea4-c2af-416e-a79d-a8b5d897af56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/138720 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/59452 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids'],\n",
       "        num_rows: 261662\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids'],\n",
       "        num_rows: 112207\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokenizado = tokenized_datasets.map(group_texts, batched=True)\n",
    "df_tokenizado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a3b955-9e5d-4385-a2c0-f8506d5d4087",
   "metadata": {},
   "source": [
    "<h3>¿Por que la solucion 4 funciona?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710e939e-f880-431d-9eae-47ecf7b397ae",
   "metadata": {},
   "source": [
    "<p>No solo se concatenara los chistes, sino tambien nuestro modelo gpt2(Spolier!) se dara cuenta que cada data no es un solo chiste, sino que pueden ser varios y los tomara por separado</p>\n",
    "<p><b>Y como se da cuenta cuando termina uno y comienza el siguiente chistes?</b></p>\n",
    "<p>Por el caracter especial del tokenizador eos_token, que fue agregado cuando tokenizamos en el siguiente codigo:</p>\n",
    "<ul>\n",
    "    <li>input_batch.append(input_ids + <b>[tokenizer.eos_token_id]</b>)</li>\n",
    "</ul>\n",
    "</p>Su representacion es de la siguiente forma:</p>\n",
    "<ul>\n",
    "    <li>>>> Texto: <|endoftext|> </li>\n",
    "    <li>>>> ID: 0</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fe0397-c2c8-4cff-a348-3fe310348528",
   "metadata": {},
   "source": [
    "Lo vamos a observar en nuestro 1er dato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22de0077-86c6-4bda-88fe-9aa6ac0a073d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stevie Wonder was in a horrendous car accident the other'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(df_tokenizado[\"train\"][0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e918022f-9737-4e61-a947-00744fd52056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ids del 1er dato: [2368, 2296, 975, 43557, 1132, 975, 41528, 11282, 1653, 1329, 410, 7012, 542, 271, 23839]\n",
      "Posiciones del 0: []\n"
     ]
    }
   ],
   "source": [
    "ids = list(df_tokenizado[\"train\"][2][\"input_ids\"])\n",
    "i_cero = [i for i, dato in enumerate(ids) if dato == 0]\n",
    "print(f\"Ids del 1er dato: {ids}\")\n",
    "print(f\"Posiciones del 0: {i_cero}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d1a782-efc8-4c86-a564-8c3cc4474672",
   "metadata": {},
   "source": [
    "Observamos que en nuestro 1er dato hay 5 ceros, en otras palabras hay 4 chistes(no necesariamente el 1er y el ultimo esten completos)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fe2c9c-a15c-4488-a0d8-0b3d213fe0c4",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb873cab-80a3-4ea5-be39-2ba9b817e25d",
   "metadata": {},
   "source": [
    "<p>Inicializo un nuevo modelo de GPT2, con las configuracion que estoy usando.</p>\n",
    "<ul>\n",
    "    <li> La longitud de contexto en 64.</li>\n",
    "    <li> La longitud del vocabulario igual al tokenizador. </li>\n",
    "    <li> La separacion de los chistes con eos_token_id.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb867ef8-846b-463b-9a43-0811825baef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, GPT2LMHeadModel, AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    vocab_size=len(tokenizer),\n",
    "    n_ctx=context_length,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "model = GPT2LMHeadModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4348f8a5-3b1b-4b4c-9dd5-a19b4288d2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4a75252-f02d-425c-ac5a-924add697d79",
   "metadata": {},
   "source": [
    "Observo los parametros a entrenar de mi modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2d7fe5c-2d84-454a-9bfd-8dbfd1f2bd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 size: 124.2M parametros\n"
     ]
    }
   ],
   "source": [
    "model_size = sum(t.numel() for t in model.parameters())\n",
    "print(f\"GPT-2 size: {model_size/1000**2:.1f}M parametros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9977b3bc-ee65-47d4-a726-99951e738a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTANTE: Al tener todas las filas de 128 tokens, no es necesario el recolector de datos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c7895d62-2449-4b98-8375-203d2bd39279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling \n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token \n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, \n",
    "                                                mlm= False # True: Si es para un modelo de lenguaje enmascarado  \n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e6fe2ac-36de-4e88-897c-6ec06afcfc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fcc8cf56-bc9e-4a5a-a087-234edb49fb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([5, 39])\n",
      "attention_mask shape: torch.Size([5, 39])\n",
      "labels shape: torch.Size([5, 39])\n"
     ]
    }
   ],
   "source": [
    "out = data_collator([tokenized_datasets[\"train\"][i] for i in range(5)])\n",
    "for key in out:\n",
    "    print(f\"{key} shape: {out[key].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d67bbf4-b6a7-4c6a-b401-ed94bc425b99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec680272-46c1-4593-afbc-9946f85ef25e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb311815-73ff-4752-aa38-d96109844038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83d61a0b4f434e11860726b6c2b186f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37bf348c-4a0a-4c3e-a1d1-75f348d3e364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "25ebec0f-3a34-4532-b94e-7d486fc086ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Cuda available: True\n",
      "CUDA device: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"Is Cuda available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA device: {torch.cuda.get_device_name(torch.cuda.current_device)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "289b1022-e2b3-4520-a1c1-b311e0d64168",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brar2\\OneDrive\\Escritorio\\Archivos\\FIUBA\\IA\\br_CLM is already a clone of https://huggingface.co/Br22/br_CLM. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"br_CLM\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=5_000,\n",
    "    logging_steps=5_000,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.1,\n",
    "    warmup_steps=1_000,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    learning_rate=5e-4,\n",
    "    save_steps=5_000,\n",
    "    fp16=True, #Importante: SOlo descomentar si tenes GPU\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "47e5ffde-c3e6-4224-b4d2-2fed2a2bfab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brar2\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 138720\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 8\n",
      "  Total optimization steps = 2167\n",
      "  Number of trainable parameters = 124242432\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2167' max='2167' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2167/2167 23:59, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2167, training_loss=5.020605153293724, metrics={'train_runtime': 1441.9811, 'train_samples_per_second': 96.201, 'train_steps_per_second': 1.503, 'total_flos': 2983363015680000.0, 'train_loss': 5.020605153293724, 'epoch': 1.0})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6f70af5c-f6af-4a98-8d3f-97c91323e9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.trainer.Trainer at 0x1be63da2d90>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "46921608-b892-4e21-9fd3-e8baf69813ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to br_CLM\n",
      "Configuration saved in br_CLM\\config.json\n",
      "Configuration saved in br_CLM\\generation_config.json\n",
      "Model weights saved in br_CLM\\pytorch_model.bin\n",
      "tokenizer config file saved in br_CLM\\tokenizer_config.json\n",
      "Special tokens file saved in br_CLM\\special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81334f195b3b4955906b26c5b7435ab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 32.0k/486M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020833ca0620431fbe4bff93499ec1d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file training_args.bin: 100%|##########| 3.37k/3.37k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "remote: Scanning LFS files of refs/heads/main for validity...        \n",
      "remote: LFS file scan complete.        \n",
      "To https://huggingface.co/Br22/br_CLM\n",
      "   7f86c2b..25d20a1  main -> main\n",
      "\n",
      "Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n",
      "To https://huggingface.co/Br22/br_CLM\n",
      "   25d20a1..44caea3  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/Br22/br_CLM/commit/25d20a166d10bcf173d0d6b2d32d6310d5331a46'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beee4aa5-e417-4056-8d46-53652843f0cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfbd7c5-5ad8-48f6-b956-ae6a18750890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "11eeacbf-a87c-4a53-95a5-b6447db972de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\brar2/.cache\\huggingface\\hub\\models--Br22--br_CLM\\snapshots\\44caea32cc2024862b30d918cee78e3d412f9b4c\\config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"Br22/br_CLM\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 15,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50000\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\brar2/.cache\\huggingface\\hub\\models--Br22--br_CLM\\snapshots\\44caea32cc2024862b30d918cee78e3d412f9b4c\\config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"Br22/br_CLM\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 15,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50000\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\brar2/.cache\\huggingface\\hub\\models--Br22--br_CLM\\snapshots\\44caea32cc2024862b30d918cee78e3d412f9b4c\\pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at Br22/br_CLM.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at C:\\Users\\brar2/.cache\\huggingface\\hub\\models--Br22--br_CLM\\snapshots\\44caea32cc2024862b30d918cee78e3d412f9b4c\\generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at C:\\Users\\brar2/.cache\\huggingface\\hub\\models--Br22--br_CLM\\snapshots\\44caea32cc2024862b30d918cee78e3d412f9b4c\\vocab.json\n",
      "loading file merges.txt from cache at C:\\Users\\brar2/.cache\\huggingface\\hub\\models--Br22--br_CLM\\snapshots\\44caea32cc2024862b30d918cee78e3d412f9b4c\\merges.txt\n",
      "loading file tokenizer.json from cache at C:\\Users\\brar2/.cache\\huggingface\\hub\\models--Br22--br_CLM\\snapshots\\44caea32cc2024862b30d918cee78e3d412f9b4c\\tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\brar2/.cache\\huggingface\\hub\\models--Br22--br_CLM\\snapshots\\44caea32cc2024862b30d918cee78e3d412f9b4c\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\brar2/.cache\\huggingface\\hub\\models--Br22--br_CLM\\snapshots\\44caea32cc2024862b30d918cee78e3d412f9b4c\\tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", model=\"Br22/br_CLM\", device=torch.device(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1f51b113-5096-4d78-9e09-86c263c58a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 50,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like you, I know you better. Dude, I don't even like my mother's or a lot. Maybe I tell it, they'll tell you about you. But I do it now. You're fat ghosts. S\n"
     ]
    }
   ],
   "source": [
    "txt=\"I like you\"\n",
    "print(pipe(txt)[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9470cf8-a306-47e9-bb97-f9dcc46855a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
